## 后端技术面试38讲
## 开篇词
其实很多看起来难以坚持、让人容易放弃的事情，并不是智力、体力或者意志力的问题，更多的是方法问题。

绝大多数新技术其实都脱胎于一些既有的技术体系。

如果你能建立起这套技术思维体系，掌握这套技术体系背后的原理，那么当你接触一个新技术的时候，就可以快速把握住这个新技术的本质特征和思路方法，然后用你的技术思维体系快速推导出这个新技术是如何实现的。这个时候你其实不需要去学习这个新技术了，而是去验证这个新技术，你会去看它的文档和代码，去验证它是不是和你推导、猜测的实现方式一致，而不是去学习它怎么用了。

### 第一性原理——建立技术体系的起点

第一性原理就是让我们抓住事物最本质的特征原理，依据事物本身的规律，去推导、分析、演绎事物的各种变化规律，进而洞悉事物在各种具体场景下的表现形式，而不是追随事物的表面现象，生搬硬套各种所谓的规矩、经验和技巧，以至于在各种纷繁复杂的冲突和纠结中迷失了方向。

软件开发技术也是非常庞杂的，各种基础技术，各种编程语言，各种工具框架，各种设计模式，各种架构方法，很容易让人觉得无所适从。就算下定决心要从基础学起，上来一本厚厚的《操作系统原理》，好不容易咬牙坚持学完，回头一看，还是各种迷茫，不知道在讲什么。继续学下去，再来一套更厚的《TCP/IP 详解》，彻底耗尽了意志力和兴趣，完全放弃。

**软件的基础原理、软件的设计原理、架构的核心原理**

软件的基础原理主要是操作系统、数据结构、数据库原理等等

软件的设计原理会讲述如何设计一个强大灵活，易复用，易维护的软件

架构的核心原理围绕目前主要的互联网分布式架构以及大数据物联网架构进行剖析

其实我学几何的这种方式就是第一性原理。第一性原理是一种思维方式，一种学习方式，一种围绕事物核心推动事物正确前进的做事方式。也许这个专栏讲到的很多知识技术你已经掌握，但是这些知识技术和软件技术最基本的原理的关系你也许不甚了解。它们从何而来，又将如何构建出新的技术？如果把这些关系和原理都理解透彻了，你会发现，日常开发用到的各种技术，你不但可以随心所欲地去使用，甚至可以重新创造。

## 01丨程序运行原理：程序是如何运行又是如何崩溃的？

### 程序是如何运行起来的

不管是文本格式的代码还是可执行的代码，都被称为程序，程序是静态的，安静地呆在磁盘上，什么也干不了。

要想让程序处理数据，完成计算任务，必须把程序从外部设备加载到内存中，并在操作系统的管理调度下交给 CPU 去执行，去运行起来，才能真正发挥软件的作用，程序运行起来以后，被称作进程。

进程除了包含可执行的程序代码，还包括进程在运行期使用的内存堆空间、栈空间、供操作系统管理用的数据结构。如下图所示：

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/89c6e3bbc44cdc042e7a8bcddb3b4398.png)

堆是一块无序的内存空间，任何时候进程需要申请内存，都会从堆空间中分配，分配到的内存地址则记录在栈中。

栈是严格的一个后进先出的数据结构，同样由操作系统维护，主要用来记录函数内部的局部变量、堆空间分配的内存空间地址等。

每次函数调用，操作系统都会在栈中创建一个栈帧（stack frame）。正在执行的函数参数、局部变量、申请的内存地址等都在当前栈帧中，也就是堆栈的顶部栈帧中。如下图所示：

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/f08d6fca893da5cac926a23f1f1aa7f7.png)

真正执行的函数永远都在栈顶。而且因为栈帧是隔离的，所以不同函数可以定义相同的变量而不会发生混乱。

### 一台计算机如何同时处理数以百计的任务

如果同时有很多个进程在执行，操作系统会将 CPU 的执行时间分成很多份，进程按照某种策略轮流在 CPU 上运行。由于现代 CPU 的计算能力非常强大，虽然每个进程都只被执行了很短一个时间，但是在外部看来却好像是所有的进程都在同时执行，每个进程似乎都独占一个 CPU 执行。

进程在生命周期中，主要有三种状态，**运行**、**就绪**、**阻塞**。

- 运行：当一个进程在 CPU 上运行时，则称该进程处于运行状态。处于运行状态的进程的数目小于等于 CPU 的数目。
- 就绪：当一个进程获得了除 CPU 以外的一切所需资源，只要得到 CPU 即可运行，则称此进程处于就绪状态，就绪状态有时候也被称为等待运行状态。
- 阻塞：也称为等待或睡眠状态，当一个进程正在等待某一事件发生（例如等待 I/O 完成，等待锁……）而暂时停止运行，这时即使把 CPU 分配给进程也无法运行，故称该进程处于阻塞状态。

不同进程轮流在 CPU 上执行，每次都要进行进程间 CPU 切换，代价是非常大的，实际上，每个用户请求对应的不是一个进程，而是一个线程。线程可以理解为轻量级的进程，在进程内创建，拥有自己的线程栈，在 CPU 上进行线程切换的代价也更小。线程在运行时，和进程一样，也有三种主要状态，从逻辑上看，进程的主要概念都可以套用到线程上。

### 系统为什么会变慢，为什么会崩溃

启动多线程，为每个用户请求分配一个处理线程的工作是在 web 容器中完成的，比如常用的 Tomcat 容器。

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/d40cc1e9a2a5ce3913670743f0543b9a.png)

真正完成最终计算的，是 CPU、内存等服务器硬件，操作系统将这些硬件进行分时（CPU）、分片（内存）管理，虚拟化成一个独享资源让 JVM 进程在其上运行。

不管你是否有意识，你开发的 web 程序都是被多线程执行的，web 开发天然就是多线程开发。

CPU 以线程为单位进行分时共享执行，可以想象代码被加载到内存空间后，有多个线程在这些代码上执行，这些线程从逻辑上看，是同时在运行的，每个线程有自己的线程栈，所有的线程栈都是完全隔离的，也就是每个方法的参数和方法内的局部变量都是隔离的，一个线程无法访问到其他线程的栈内数据。

但是当某些代码修改内存堆里的数据的时候，如果有多个线程在同时执行，就可能会出现同时修改数据的情况，这就是人们常说的**线程安全**问题。

多个线程访问共享资源的这段代码被称为**临界区**，解决线程安全问题的主要方法是使用锁，将临界区的代码加锁，只有获得锁的线程才能执行临界区代码。

```
lock.lock();  //线程获得锁
i++;  //临界区代码，i位于堆中
lock.unlock();  //线程释放锁
```

如果当前线程执行到第一行，获得锁的代码的时候，锁已经被其他线程获取并没有释放，那么这个线程就会进入阻塞状态，等待前面释放锁的线程将自己唤醒重新获得锁。

锁会引起线程阻塞，如果有很多线程同时在运行，那么就会出现线程排队等待锁的情况，线程无法并行执行，系统响应速度就会变慢。此外 I/O 操作也会引起阻塞，对数据库连接的获取也可能会引起阻塞。目前典型的 web 应用都是基于 RDBMS 关系数据库的，web 应用要想访问数据库，必须获得数据库连接，而受数据库资源限制，每个 web 应用能建立的数据库的连接是有限的，如果并发线程数超过了连接数，那么就会有部分线程无法获得连接而进入阻塞，等待其他线程释放连接后才能访问数据库，并发的线程数越多，等待连接的时间也越多，从 web 请求者角度看，响应时间变长，**系统变慢**。

被阻塞的线程越多，占据的系统资源也越多，这些被阻塞的线程既不能继续执行，也不能释放当前已经占据的资源，在系统中一边等待一边消耗资源，如果阻塞的线程数超过了某个系统资源的极限，就会导致系统宕机，**应用崩溃**。

解决系统因高并发而导致的响应变慢、应用崩溃的主要手段是使用**分布式系统架构**，用更多的服务器构成一个集群，以便共同处理用户的并发请求，保证每台服务器的并发负载不会太高。此外必要时还需要在请求入口处进行**限流**，减小系统的并发请求数；在应用内进行业务**降级**，减小线程的资源消耗。

## 02丨数据结构原理：Hash表的时间复杂度为什么是O(1)？

