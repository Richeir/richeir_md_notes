## 后端技术面试38讲
## 开篇词
其实很多看起来难以坚持、让人容易放弃的事情，并不是智力、体力或者意志力的问题，更多的是方法问题。

绝大多数新技术其实都脱胎于一些既有的技术体系。

如果你能建立起这套技术思维体系，掌握这套技术体系背后的原理，那么当你接触一个新技术的时候，就可以快速把握住这个新技术的本质特征和思路方法，然后用你的技术思维体系快速推导出这个新技术是如何实现的。这个时候你其实不需要去学习这个新技术了，而是去验证这个新技术，你会去看它的文档和代码，去验证它是不是和你推导、猜测的实现方式一致，而不是去学习它怎么用了。

### 第一性原理——建立技术体系的起点

第一性原理就是让我们抓住事物最本质的特征原理，依据事物本身的规律，去推导、分析、演绎事物的各种变化规律，进而洞悉事物在各种具体场景下的表现形式，而不是追随事物的表面现象，生搬硬套各种所谓的规矩、经验和技巧，以至于在各种纷繁复杂的冲突和纠结中迷失了方向。

软件开发技术也是非常庞杂的，各种基础技术，各种编程语言，各种工具框架，各种设计模式，各种架构方法，很容易让人觉得无所适从。就算下定决心要从基础学起，上来一本厚厚的《操作系统原理》，好不容易咬牙坚持学完，回头一看，还是各种迷茫，不知道在讲什么。继续学下去，再来一套更厚的《TCP/IP 详解》，彻底耗尽了意志力和兴趣，完全放弃。

**软件的基础原理、软件的设计原理、架构的核心原理**

软件的基础原理主要是操作系统、数据结构、数据库原理等等

软件的设计原理会讲述如何设计一个强大灵活，易复用，易维护的软件

架构的核心原理围绕目前主要的互联网分布式架构以及大数据物联网架构进行剖析

其实我学几何的这种方式就是第一性原理。第一性原理是一种思维方式，一种学习方式，一种围绕事物核心推动事物正确前进的做事方式。也许这个专栏讲到的很多知识技术你已经掌握，但是这些知识技术和软件技术最基本的原理的关系你也许不甚了解。它们从何而来，又将如何构建出新的技术？如果把这些关系和原理都理解透彻了，你会发现，日常开发用到的各种技术，你不但可以随心所欲地去使用，甚至可以重新创造。

## 01丨程序运行原理：程序是如何运行又是如何崩溃的？

### 程序是如何运行起来的

不管是文本格式的代码还是可执行的代码，都被称为程序，程序是静态的，安静地呆在磁盘上，什么也干不了。

要想让程序处理数据，完成计算任务，必须把程序从外部设备加载到内存中，并在操作系统的管理调度下交给 CPU 去执行，去运行起来，才能真正发挥软件的作用，程序运行起来以后，被称作进程。

进程除了包含可执行的程序代码，还包括进程在运行期使用的内存堆空间、栈空间、供操作系统管理用的数据结构。如下图所示：

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/89c6e3bbc44cdc042e7a8bcddb3b4398.png)

堆是一块无序的内存空间，任何时候进程需要申请内存，都会从堆空间中分配，分配到的内存地址则记录在栈中。

栈是严格的一个后进先出的数据结构，同样由操作系统维护，主要用来记录函数内部的局部变量、堆空间分配的内存空间地址等。

每次函数调用，操作系统都会在栈中创建一个栈帧（stack frame）。正在执行的函数参数、局部变量、申请的内存地址等都在当前栈帧中，也就是堆栈的顶部栈帧中。如下图所示：

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/f08d6fca893da5cac926a23f1f1aa7f7.png)

真正执行的函数永远都在栈顶。而且因为栈帧是隔离的，所以不同函数可以定义相同的变量而不会发生混乱。

### 一台计算机如何同时处理数以百计的任务

如果同时有很多个进程在执行，操作系统会将 CPU 的执行时间分成很多份，进程按照某种策略轮流在 CPU 上运行。由于现代 CPU 的计算能力非常强大，虽然每个进程都只被执行了很短一个时间，但是在外部看来却好像是所有的进程都在同时执行，每个进程似乎都独占一个 CPU 执行。

进程在生命周期中，主要有三种状态，**运行**、**就绪**、**阻塞**。

- 运行：当一个进程在 CPU 上运行时，则称该进程处于运行状态。处于运行状态的进程的数目小于等于 CPU 的数目。
- 就绪：当一个进程获得了除 CPU 以外的一切所需资源，只要得到 CPU 即可运行，则称此进程处于就绪状态，就绪状态有时候也被称为等待运行状态。
- 阻塞：也称为等待或睡眠状态，当一个进程正在等待某一事件发生（例如等待 I/O 完成，等待锁……）而暂时停止运行，这时即使把 CPU 分配给进程也无法运行，故称该进程处于阻塞状态。

不同进程轮流在 CPU 上执行，每次都要进行进程间 CPU 切换，代价是非常大的，实际上，每个用户请求对应的不是一个进程，而是一个线程。线程可以理解为轻量级的进程，在进程内创建，拥有自己的线程栈，在 CPU 上进行线程切换的代价也更小。线程在运行时，和进程一样，也有三种主要状态，从逻辑上看，进程的主要概念都可以套用到线程上。

### 系统为什么会变慢，为什么会崩溃

启动多线程，为每个用户请求分配一个处理线程的工作是在 web 容器中完成的，比如常用的 Tomcat 容器。

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/d40cc1e9a2a5ce3913670743f0543b9a.png)

真正完成最终计算的，是 CPU、内存等服务器硬件，操作系统将这些硬件进行分时（CPU）、分片（内存）管理，虚拟化成一个独享资源让 JVM 进程在其上运行。

不管你是否有意识，你开发的 web 程序都是被多线程执行的，web 开发天然就是多线程开发。

CPU 以线程为单位进行分时共享执行，可以想象代码被加载到内存空间后，有多个线程在这些代码上执行，这些线程从逻辑上看，是同时在运行的，每个线程有自己的线程栈，所有的线程栈都是完全隔离的，也就是每个方法的参数和方法内的局部变量都是隔离的，一个线程无法访问到其他线程的栈内数据。

但是当某些代码修改内存堆里的数据的时候，如果有多个线程在同时执行，就可能会出现同时修改数据的情况，这就是人们常说的**线程安全**问题。

多个线程访问共享资源的这段代码被称为**临界区**，解决线程安全问题的主要方法是使用锁，将临界区的代码加锁，只有获得锁的线程才能执行临界区代码。

```
lock.lock();  //线程获得锁
i++;  //临界区代码，i位于堆中
lock.unlock();  //线程释放锁
```

如果当前线程执行到第一行，获得锁的代码的时候，锁已经被其他线程获取并没有释放，那么这个线程就会进入阻塞状态，等待前面释放锁的线程将自己唤醒重新获得锁。

锁会引起线程阻塞，如果有很多线程同时在运行，那么就会出现线程排队等待锁的情况，线程无法并行执行，系统响应速度就会变慢。此外 I/O 操作也会引起阻塞，对数据库连接的获取也可能会引起阻塞。目前典型的 web 应用都是基于 RDBMS 关系数据库的，web 应用要想访问数据库，必须获得数据库连接，而受数据库资源限制，每个 web 应用能建立的数据库的连接是有限的，如果并发线程数超过了连接数，那么就会有部分线程无法获得连接而进入阻塞，等待其他线程释放连接后才能访问数据库，并发的线程数越多，等待连接的时间也越多，从 web 请求者角度看，响应时间变长，**系统变慢**。

被阻塞的线程越多，占据的系统资源也越多，这些被阻塞的线程既不能继续执行，也不能释放当前已经占据的资源，在系统中一边等待一边消耗资源，如果阻塞的线程数超过了某个系统资源的极限，就会导致系统宕机，**应用崩溃**。

解决系统因高并发而导致的响应变慢、应用崩溃的主要手段是使用**分布式系统架构**，用更多的服务器构成一个集群，以便共同处理用户的并发请求，保证每台服务器的并发负载不会太高。此外必要时还需要在请求入口处进行**限流**，减小系统的并发请求数；在应用内进行业务**降级**，减小线程的资源消耗。

## 02丨数据结构原理：Hash表的时间复杂度为什么是O(1)？

此后十年间，我用这个问题面试了大约上千人，这些面试经历让我更加坚定了一个想法：这个问题就是候选人技术水平的一个分水岭，是证明一个技术人员是否具有必备专业技能和技术悟性的一个门槛。这个槛过不去是不可接受的。

为什么呢？我很难相信，如果基本的数据结构没有掌握好，如何能开发好一个稍微复杂一点的程序？

### 数组

数组是最常用的数据结构，创建数组必须要内存中一块连续的空间，并且数组中必须存放相同的数据类型。

随机快速读写是数组的一个重要特性，但是要随机访问数据，必须知道数据在数组中的下标。如果我们只是知道数据的值，想要在数组中找到这个值，那么就只能遍历整个数组，时间复杂度为 O(N)。

### 链表

不同于数组必须要连续的内存空间，链表可以使用零散的内存空间存储数据。不过，因为链表在内存中的数据不是连续的，所以链表中的每个数据元素都必须包含一个指向下一个数据元素的内存地址指针。

因为链表是不连续存储的，要想在链表中查找一个数据，只能遍历链表，所以链表的查找复杂度总是 O(N)。

但是正因为链表是不连续存储的，所以在链表中插入或者删除一个数据是非常容易的，只要找到要插入（删除）的位置，修改链表指针就可以了。

相比在链表中轻易插入、删除一个元素这种简单的操作，如果我们要想在数组中插入、删除一个数据，就会改变数组连续内存空间的大小，需要重新分配内存空间，这样要复杂得多。

### Hash 表

Hash 表的物理存储其实是一个数组，如果我们能够根据 Key 计算出数组下标，那么就可以快速在数组中查找到需要的 Key 和 Value。

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/e2d3191b087d902980595aeb1be79dcb.png)

上图这个例子中，Key 是字符串 abc，Value 是字符串 hello。我们先计算 Key 的哈希值，得到 101 这样一个整型值。然后用 101 对 8 取模，这个 8 是哈希表数组的长度。

### 但是如果不同的 Key 计算出来的数组下标相同怎么办？

HashCode101 对 8 取模余数是 5，HashCode109 对 8 取模余数还是 5，也就是说，不同的 Key 有可能计算得到相同的数组下标，这就是所谓的 Hash 冲突，解决 Hash 冲突常用的方法是链表法。

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/ea89bec385ebfe5c03b306deead03c9a.png)

因为有 Hash 冲突的存在，所以“Hash 表的时间复杂度为什么是 O(1)？”这句话并不严谨，极端情况下，如果所有 Key 的数组下标都冲突，那么 Hash 表就退化为一条链表，查询的时间复杂度是 O(N)。但是作为一个面试题，“Hash 表的时间复杂度为什么是 O(1)”是没有问题的。

### 栈

栈就是在线性表的基础上加了这样的操作限制条件：后面添加的数据，在删除的时候必须先删除，即通常所说的“后进先出”。

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/85752adc1fc26453e2236f0a8b01c081.png)

我们上篇提到的程序运行过程中，方法的调用需要用栈来管理每个方法的工作区，这样，不管方法如何嵌套调用，栈顶元素始终是当前正在执行的方法的工作区。

### 队列

队列也是一种操作受限的线性表，栈是后进先出，而队列是先进先出。

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/a396ab50312b5faa29c7b93f6ad4b7a5.png)

现实中也是如此，超市在货架上摆放食品的时候，其实是按照队列摆放的，而不是堆栈摆放的。工作人员在上架新食品的时候，总是把新食品摆在后面，使食品成为一个队列，以便让以前上架的食品被尽快卖出。

### 树

数组、链表、栈、队列都是线性表，也就是每个数据元素都只有一个前驱，一个后继。而树则是非线性表，树是这样的。

![img](05_%E5%90%8E%E7%AB%AF%E9%9D%A2%E8%AF%9538%E8%AE%B2.assets/88906ad45504ae3d195dadc9b7a455cd.png)

软件开发中，也有很多地方用到树，比如我们要开发一个 OA 系统，部门的组织结构就是一棵树；我们编写的程序在编译的时候，第一步就是将程序代码生成抽象语法树。传统上树的遍历使用递归的方式，而我个人更喜欢用设计模式中的组合模式进行树的遍历。

## 03丨Java虚拟机原理：JVM为什么被称为机器（machine）？

